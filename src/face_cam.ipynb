{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from disk: trainset\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlrd\n",
    "import pickle as Pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "   \n",
    "root_path = '/Users/chenguanghao/Desktop/Amanda/Weakly_detector'\n",
    "image_path = os.path.join(root_path,'datasets/face_impression/images')\n",
    "trainset_path = os.path.join(root_path,'datasets/face_impression/train.pickle')\n",
    "weight_path = os.path.join(root_path,'trained_models/VGG/caffe_layers_value.pickle')\n",
    "pretrained_model = None\n",
    "model_path = os.path.join(root_path,'trained_models/VGG/')\n",
    "saved_model_name = 'model-1'\n",
    "\n",
    "def data_augmentation(file):\n",
    "    image = cv2.imread(os.path.join(image_path,file))\n",
    "    horizontal_img = image.copy()\n",
    "    horizontal_img = cv2.flip(horizontal_img,1)\n",
    "    newname = os.path.splitext(file)[0]+\"_flip.jpg\"\n",
    "    cv2.imwrite(os.path.join(image_path,newname),horizontal_img)\n",
    "    return newname\n",
    "    \n",
    "    \n",
    "if not os.path.exists( trainset_path ):\n",
    "    data = xlrd.open_workbook(os.path.join(root_path,'datasets/face_impression/psychology-attributes.xlsx'))\n",
    "    table = data.sheets()[1]\n",
    "    nrows = table.nrows\n",
    "    raw_data = []\n",
    "    filename_list = []\n",
    "    for i in range(1,nrows):\n",
    "        filename_list.append(table.row_values(i)[0])\n",
    "        newname = data_augmentation(table.row_values(i)[0])\n",
    "        filename_list.append(newname)\n",
    "        raw_data.append(np.array(table.row_values(i)[2:17]+table.row_values(i)[20:44]+table.row_values(i)[47:]))\n",
    "        raw_data.append(np.array(table.row_values(i)[2:17]+table.row_values(i)[20:44]+table.row_values(i)[47:]))\n",
    "    trainset = pd.DataFrame({'image_path': filename_list})\n",
    "    trainset[\"label\"] = raw_data\n",
    "    trainset.to_pickle(trainset_path)\n",
    "    print ('Creating the trainSet')\n",
    "else:\n",
    "    trainset = pd.read_pickle(trainset_path)\n",
    "    print ('Read from disk: trainset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google_1_Danielle Goble_5_oval.jpg</td>\n",
       "      <td>[3.933333, 6.0, 6.285714, 5.933333, 5.933333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google_1_Danielle Goble_5_oval_flip.jpg</td>\n",
       "      <td>[3.933333, 6.0, 6.285714, 5.933333, 5.933333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google_1_Phillip Owensby_9_oval.jpg</td>\n",
       "      <td>[2.933333, 3.866667, 6.466667, 5.0, 5.0, 2.066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google_1_Phillip Owensby_9_oval_flip.jpg</td>\n",
       "      <td>[2.933333, 3.866667, 6.466667, 5.0, 5.0, 2.066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google_1_Douglas Ziegler_3_oval.jpg</td>\n",
       "      <td>[2.866667, 4.2, 6.666667, 4.733333, 4.733333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Google_1_Douglas Ziegler_3_oval_flip.jpg</td>\n",
       "      <td>[2.866667, 4.2, 6.666667, 4.733333, 4.733333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Google_1_Donald Sauls_11_oval.jpg</td>\n",
       "      <td>[4.785714, 4.733333, 5.4, 4.4, 4.4, 5.4, 5.571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Google_1_Donald Sauls_11_oval_flip.jpg</td>\n",
       "      <td>[4.785714, 4.733333, 5.4, 4.4, 4.4, 5.4, 5.571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google_1_Eric Harman_5_oval.jpg</td>\n",
       "      <td>[4.066667, 4.933333, 5.866667, 4.466667, 4.466...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Google_1_Eric Harman_5_oval_flip.jpg</td>\n",
       "      <td>[4.066667, 4.933333, 5.866667, 4.466667, 4.466...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Google_1_Peter Grigsby_13_oval.jpg</td>\n",
       "      <td>[3.071429, 2.642857, 7.071429, 4.857143, 4.857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Google_1_Peter Grigsby_13_oval_flip.jpg</td>\n",
       "      <td>[3.071429, 2.642857, 7.071429, 4.857143, 4.857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Google_1_Nathan Beauregard_3_oval.jpg</td>\n",
       "      <td>[2.933333, 3.714286, 6.066667, 3.6, 3.6, 1.933...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Google_1_Nathan Beauregard_3_oval_flip.jpg</td>\n",
       "      <td>[2.933333, 3.714286, 6.066667, 3.6, 3.6, 1.933...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Google_1_Bryan Nava_1_oval.jpg</td>\n",
       "      <td>[5.0, 5.4, 4.8, 5.466667, 5.466667, 7.4, 5.4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Google_1_Bryan Nava_1_oval_flip.jpg</td>\n",
       "      <td>[5.0, 5.4, 4.8, 5.466667, 5.466667, 7.4, 5.4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Google_1_Travis Streeter_13_oval.jpg</td>\n",
       "      <td>[3.533333, 3.571429, 6.466667, 5.6, 5.6, 2.866...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Google_1_Travis Streeter_13_oval_flip.jpg</td>\n",
       "      <td>[3.533333, 3.571429, 6.466667, 5.6, 5.6, 2.866...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Brian_Furlong_5_oval.jpg</td>\n",
       "      <td>[3.466667, 5.0, 6.266667, 5.533333, 5.533333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Brian_Furlong_5_oval_flip.jpg</td>\n",
       "      <td>[3.466667, 5.0, 6.266667, 5.533333, 5.533333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Google_1_Paul Wills_11_oval.jpg</td>\n",
       "      <td>[3.466667, 4.133333, 6.2, 4.733333, 4.733333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Google_1_Paul Wills_11_oval_flip.jpg</td>\n",
       "      <td>[3.466667, 4.133333, 6.2, 4.733333, 4.733333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Google_1_Jesse Lindgren_7_oval.jpg</td>\n",
       "      <td>[3.933333, 3.333333, 5.666667, 5.6, 5.6, 3.466...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Google_1_Jesse Lindgren_7_oval_flip.jpg</td>\n",
       "      <td>[3.933333, 3.333333, 5.666667, 5.6, 5.6, 3.466...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Google_1_David Ferris_3_oval.jpg</td>\n",
       "      <td>[5.066667, 4.4, 5.533333, 5.933333, 5.933333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Google_1_David Ferris_3_oval_flip.jpg</td>\n",
       "      <td>[5.066667, 4.4, 5.533333, 5.933333, 5.933333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Google_1_Bonnie Fullmer_5_oval.jpg</td>\n",
       "      <td>[4.733333, 6.4, 6.266667, 5.6, 5.6, 6.066667, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Google_1_Bonnie Fullmer_5_oval_flip.jpg</td>\n",
       "      <td>[4.733333, 6.4, 6.266667, 5.6, 5.6, 6.066667, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Google_1_Keith Priester_5_oval.jpg</td>\n",
       "      <td>[3.466667, 4.2, 5.666667, 4.933333, 4.933333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Google_1_Keith Priester_5_oval_flip.jpg</td>\n",
       "      <td>[3.466667, 4.2, 5.666667, 4.933333, 4.933333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>Google_1_Karen Markey_16_oval.jpg</td>\n",
       "      <td>[4.230769, 3.076923, 6.923077, 5.384615, 5.384...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>Google_1_Karen Markey_16_oval_flip.jpg</td>\n",
       "      <td>[4.230769, 3.076923, 6.923077, 5.384615, 5.384...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>Google_1_Samuel Leggett_1_oval.jpg</td>\n",
       "      <td>[5.0, 5.071429, 4.714286, 5.214286, 5.214286, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4415</th>\n",
       "      <td>Google_1_Samuel Leggett_1_oval_flip.jpg</td>\n",
       "      <td>[5.0, 5.071429, 4.714286, 5.214286, 5.214286, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>Google_1_Stephanie Hammock_5_oval.jpg</td>\n",
       "      <td>[5.0, 3.666667, 4.666667, 5.8, 5.8, 3.666667, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4417</th>\n",
       "      <td>Google_1_Stephanie Hammock_5_oval_flip.jpg</td>\n",
       "      <td>[5.0, 3.666667, 4.666667, 5.8, 5.8, 3.666667, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4418</th>\n",
       "      <td>Google_1_Lori Weisman_12_oval.jpg</td>\n",
       "      <td>[4.642857, 3.714286, 6.5, 4.571429, 4.571429, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>Google_1_Lori Weisman_12_oval_flip.jpg</td>\n",
       "      <td>[4.642857, 3.714286, 6.5, 4.571429, 4.571429, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>Google_1_Cynthia Futrell_1_oval.jpg</td>\n",
       "      <td>[4.733333, 4.066667, 6.066667, 4.533333, 4.533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>Google_1_Cynthia Futrell_1_oval_flip.jpg</td>\n",
       "      <td>[4.733333, 4.066667, 6.066667, 4.533333, 4.533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>Google_1_Grace Kuhns_1_oval.jpg</td>\n",
       "      <td>[5.533333, 4.2, 3.6, 4.266667, 4.266667, 4.466...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>Google_1_Grace Kuhns_1_oval_flip.jpg</td>\n",
       "      <td>[5.533333, 4.2, 3.6, 4.266667, 4.266667, 4.466...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>Google_1_Roy Tanaka_3_oval.jpg</td>\n",
       "      <td>[4.214286, 5.071429, 6.285714, 3.857143, 3.857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>Google_1_Roy Tanaka_3_oval_flip.jpg</td>\n",
       "      <td>[4.214286, 5.071429, 6.285714, 3.857143, 3.857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>Google_1_Shawn Ginn_5_oval.jpg</td>\n",
       "      <td>[3.714286, 4.0, 4.571429, 5.785714, 5.785714, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>Google_1_Shawn Ginn_5_oval_flip.jpg</td>\n",
       "      <td>[3.714286, 4.0, 4.571429, 5.785714, 5.785714, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>Google_1_Kimberly Mccown_5_oval.jpg</td>\n",
       "      <td>[4.2, 4.933333, 4.8, 4.733333, 4.733333, 3.866...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>Google_1_Kimberly Mccown_5_oval_flip.jpg</td>\n",
       "      <td>[4.2, 4.933333, 4.8, 4.733333, 4.733333, 3.866...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>Google_1_Manuel Cleveland_19_oval.jpg</td>\n",
       "      <td>[4.333333, 4.0, 5.266667, 5.066667, 5.066667, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>Google_1_Manuel Cleveland_19_oval_flip.jpg</td>\n",
       "      <td>[4.333333, 4.0, 5.266667, 5.066667, 5.066667, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>Google_1_Alison Summerville_3_oval.jpg</td>\n",
       "      <td>[3.4, 3.333333, 5.6, 4.133333, 4.133333, 3.8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>Google_1_Alison Summerville_3_oval_flip.jpg</td>\n",
       "      <td>[3.4, 3.333333, 5.6, 4.133333, 4.133333, 3.8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>Google_1_Douglas Yun_3_oval.jpg</td>\n",
       "      <td>[4.4, 4.4, 4.933333, 4.866667, 4.866667, 5.866...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>Google_1_Douglas Yun_3_oval_flip.jpg</td>\n",
       "      <td>[4.4, 4.4, 4.933333, 4.866667, 4.866667, 5.866...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>Google_1_Wayne Barrios_9_oval.jpg</td>\n",
       "      <td>[3.8, 3.666667, 4.8, 5.466667, 5.466667, 2.266...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>Google_1_Wayne Barrios_9_oval_flip.jpg</td>\n",
       "      <td>[3.8, 3.666667, 4.8, 5.466667, 5.466667, 2.266...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>Google_1_Jennie Kissinger_15_oval.jpg</td>\n",
       "      <td>[4.0, 4.0, 5.4, 5.466667, 5.466667, 3.266667, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>Google_1_Jennie Kissinger_15_oval_flip.jpg</td>\n",
       "      <td>[4.0, 4.0, 5.4, 5.466667, 5.466667, 3.266667, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>Google_1_Eileen Burd_7_oval.jpg</td>\n",
       "      <td>[4.0, 4.857143, 5.642857, 5.285714, 5.285714, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>Google_1_Eileen Burd_7_oval_flip.jpg</td>\n",
       "      <td>[4.0, 4.857143, 5.642857, 5.285714, 5.285714, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4442 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_path  \\\n",
       "0              Google_1_Danielle Goble_5_oval.jpg   \n",
       "1         Google_1_Danielle Goble_5_oval_flip.jpg   \n",
       "2             Google_1_Phillip Owensby_9_oval.jpg   \n",
       "3        Google_1_Phillip Owensby_9_oval_flip.jpg   \n",
       "4             Google_1_Douglas Ziegler_3_oval.jpg   \n",
       "5        Google_1_Douglas Ziegler_3_oval_flip.jpg   \n",
       "6               Google_1_Donald Sauls_11_oval.jpg   \n",
       "7          Google_1_Donald Sauls_11_oval_flip.jpg   \n",
       "8                 Google_1_Eric Harman_5_oval.jpg   \n",
       "9            Google_1_Eric Harman_5_oval_flip.jpg   \n",
       "10             Google_1_Peter Grigsby_13_oval.jpg   \n",
       "11        Google_1_Peter Grigsby_13_oval_flip.jpg   \n",
       "12          Google_1_Nathan Beauregard_3_oval.jpg   \n",
       "13     Google_1_Nathan Beauregard_3_oval_flip.jpg   \n",
       "14                 Google_1_Bryan Nava_1_oval.jpg   \n",
       "15            Google_1_Bryan Nava_1_oval_flip.jpg   \n",
       "16           Google_1_Travis Streeter_13_oval.jpg   \n",
       "17      Google_1_Travis Streeter_13_oval_flip.jpg   \n",
       "18                       Brian_Furlong_5_oval.jpg   \n",
       "19                  Brian_Furlong_5_oval_flip.jpg   \n",
       "20                Google_1_Paul Wills_11_oval.jpg   \n",
       "21           Google_1_Paul Wills_11_oval_flip.jpg   \n",
       "22             Google_1_Jesse Lindgren_7_oval.jpg   \n",
       "23        Google_1_Jesse Lindgren_7_oval_flip.jpg   \n",
       "24               Google_1_David Ferris_3_oval.jpg   \n",
       "25          Google_1_David Ferris_3_oval_flip.jpg   \n",
       "26             Google_1_Bonnie Fullmer_5_oval.jpg   \n",
       "27        Google_1_Bonnie Fullmer_5_oval_flip.jpg   \n",
       "28             Google_1_Keith Priester_5_oval.jpg   \n",
       "29        Google_1_Keith Priester_5_oval_flip.jpg   \n",
       "...                                           ...   \n",
       "4412            Google_1_Karen Markey_16_oval.jpg   \n",
       "4413       Google_1_Karen Markey_16_oval_flip.jpg   \n",
       "4414           Google_1_Samuel Leggett_1_oval.jpg   \n",
       "4415      Google_1_Samuel Leggett_1_oval_flip.jpg   \n",
       "4416        Google_1_Stephanie Hammock_5_oval.jpg   \n",
       "4417   Google_1_Stephanie Hammock_5_oval_flip.jpg   \n",
       "4418            Google_1_Lori Weisman_12_oval.jpg   \n",
       "4419       Google_1_Lori Weisman_12_oval_flip.jpg   \n",
       "4420          Google_1_Cynthia Futrell_1_oval.jpg   \n",
       "4421     Google_1_Cynthia Futrell_1_oval_flip.jpg   \n",
       "4422              Google_1_Grace Kuhns_1_oval.jpg   \n",
       "4423         Google_1_Grace Kuhns_1_oval_flip.jpg   \n",
       "4424               Google_1_Roy Tanaka_3_oval.jpg   \n",
       "4425          Google_1_Roy Tanaka_3_oval_flip.jpg   \n",
       "4426               Google_1_Shawn Ginn_5_oval.jpg   \n",
       "4427          Google_1_Shawn Ginn_5_oval_flip.jpg   \n",
       "4428          Google_1_Kimberly Mccown_5_oval.jpg   \n",
       "4429     Google_1_Kimberly Mccown_5_oval_flip.jpg   \n",
       "4430        Google_1_Manuel Cleveland_19_oval.jpg   \n",
       "4431   Google_1_Manuel Cleveland_19_oval_flip.jpg   \n",
       "4432       Google_1_Alison Summerville_3_oval.jpg   \n",
       "4433  Google_1_Alison Summerville_3_oval_flip.jpg   \n",
       "4434              Google_1_Douglas Yun_3_oval.jpg   \n",
       "4435         Google_1_Douglas Yun_3_oval_flip.jpg   \n",
       "4436            Google_1_Wayne Barrios_9_oval.jpg   \n",
       "4437       Google_1_Wayne Barrios_9_oval_flip.jpg   \n",
       "4438        Google_1_Jennie Kissinger_15_oval.jpg   \n",
       "4439   Google_1_Jennie Kissinger_15_oval_flip.jpg   \n",
       "4440              Google_1_Eileen Burd_7_oval.jpg   \n",
       "4441         Google_1_Eileen Burd_7_oval_flip.jpg   \n",
       "\n",
       "                                                  label  \n",
       "0     [3.933333, 6.0, 6.285714, 5.933333, 5.933333, ...  \n",
       "1     [3.933333, 6.0, 6.285714, 5.933333, 5.933333, ...  \n",
       "2     [2.933333, 3.866667, 6.466667, 5.0, 5.0, 2.066...  \n",
       "3     [2.933333, 3.866667, 6.466667, 5.0, 5.0, 2.066...  \n",
       "4     [2.866667, 4.2, 6.666667, 4.733333, 4.733333, ...  \n",
       "5     [2.866667, 4.2, 6.666667, 4.733333, 4.733333, ...  \n",
       "6     [4.785714, 4.733333, 5.4, 4.4, 4.4, 5.4, 5.571...  \n",
       "7     [4.785714, 4.733333, 5.4, 4.4, 4.4, 5.4, 5.571...  \n",
       "8     [4.066667, 4.933333, 5.866667, 4.466667, 4.466...  \n",
       "9     [4.066667, 4.933333, 5.866667, 4.466667, 4.466...  \n",
       "10    [3.071429, 2.642857, 7.071429, 4.857143, 4.857...  \n",
       "11    [3.071429, 2.642857, 7.071429, 4.857143, 4.857...  \n",
       "12    [2.933333, 3.714286, 6.066667, 3.6, 3.6, 1.933...  \n",
       "13    [2.933333, 3.714286, 6.066667, 3.6, 3.6, 1.933...  \n",
       "14    [5.0, 5.4, 4.8, 5.466667, 5.466667, 7.4, 5.4, ...  \n",
       "15    [5.0, 5.4, 4.8, 5.466667, 5.466667, 7.4, 5.4, ...  \n",
       "16    [3.533333, 3.571429, 6.466667, 5.6, 5.6, 2.866...  \n",
       "17    [3.533333, 3.571429, 6.466667, 5.6, 5.6, 2.866...  \n",
       "18    [3.466667, 5.0, 6.266667, 5.533333, 5.533333, ...  \n",
       "19    [3.466667, 5.0, 6.266667, 5.533333, 5.533333, ...  \n",
       "20    [3.466667, 4.133333, 6.2, 4.733333, 4.733333, ...  \n",
       "21    [3.466667, 4.133333, 6.2, 4.733333, 4.733333, ...  \n",
       "22    [3.933333, 3.333333, 5.666667, 5.6, 5.6, 3.466...  \n",
       "23    [3.933333, 3.333333, 5.666667, 5.6, 5.6, 3.466...  \n",
       "24    [5.066667, 4.4, 5.533333, 5.933333, 5.933333, ...  \n",
       "25    [5.066667, 4.4, 5.533333, 5.933333, 5.933333, ...  \n",
       "26    [4.733333, 6.4, 6.266667, 5.6, 5.6, 6.066667, ...  \n",
       "27    [4.733333, 6.4, 6.266667, 5.6, 5.6, 6.066667, ...  \n",
       "28    [3.466667, 4.2, 5.666667, 4.933333, 4.933333, ...  \n",
       "29    [3.466667, 4.2, 5.666667, 4.933333, 4.933333, ...  \n",
       "...                                                 ...  \n",
       "4412  [4.230769, 3.076923, 6.923077, 5.384615, 5.384...  \n",
       "4413  [4.230769, 3.076923, 6.923077, 5.384615, 5.384...  \n",
       "4414  [5.0, 5.071429, 4.714286, 5.214286, 5.214286, ...  \n",
       "4415  [5.0, 5.071429, 4.714286, 5.214286, 5.214286, ...  \n",
       "4416  [5.0, 3.666667, 4.666667, 5.8, 5.8, 3.666667, ...  \n",
       "4417  [5.0, 3.666667, 4.666667, 5.8, 5.8, 3.666667, ...  \n",
       "4418  [4.642857, 3.714286, 6.5, 4.571429, 4.571429, ...  \n",
       "4419  [4.642857, 3.714286, 6.5, 4.571429, 4.571429, ...  \n",
       "4420  [4.733333, 4.066667, 6.066667, 4.533333, 4.533...  \n",
       "4421  [4.733333, 4.066667, 6.066667, 4.533333, 4.533...  \n",
       "4422  [5.533333, 4.2, 3.6, 4.266667, 4.266667, 4.466...  \n",
       "4423  [5.533333, 4.2, 3.6, 4.266667, 4.266667, 4.466...  \n",
       "4424  [4.214286, 5.071429, 6.285714, 3.857143, 3.857...  \n",
       "4425  [4.214286, 5.071429, 6.285714, 3.857143, 3.857...  \n",
       "4426  [3.714286, 4.0, 4.571429, 5.785714, 5.785714, ...  \n",
       "4427  [3.714286, 4.0, 4.571429, 5.785714, 5.785714, ...  \n",
       "4428  [4.2, 4.933333, 4.8, 4.733333, 4.733333, 3.866...  \n",
       "4429  [4.2, 4.933333, 4.8, 4.733333, 4.733333, 3.866...  \n",
       "4430  [4.333333, 4.0, 5.266667, 5.066667, 5.066667, ...  \n",
       "4431  [4.333333, 4.0, 5.266667, 5.066667, 5.066667, ...  \n",
       "4432  [3.4, 3.333333, 5.6, 4.133333, 4.133333, 3.8, ...  \n",
       "4433  [3.4, 3.333333, 5.6, 4.133333, 4.133333, 3.8, ...  \n",
       "4434  [4.4, 4.4, 4.933333, 4.866667, 4.866667, 5.866...  \n",
       "4435  [4.4, 4.4, 4.933333, 4.866667, 4.866667, 5.866...  \n",
       "4436  [3.8, 3.666667, 4.8, 5.466667, 5.466667, 2.266...  \n",
       "4437  [3.8, 3.666667, 4.8, 5.466667, 5.466667, 2.266...  \n",
       "4438  [4.0, 4.0, 5.4, 5.466667, 5.466667, 3.266667, ...  \n",
       "4439  [4.0, 4.0, 5.4, 5.466667, 5.466667, 3.266667, ...  \n",
       "4440  [4.0, 4.857143, 5.642857, 5.285714, 5.285714, ...  \n",
       "4441  [4.0, 4.857143, 5.642857, 5.285714, 5.285714, ...  \n",
       "\n",
       "[4442 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image( path ):\n",
    "    try:\n",
    "        img = skimage.io.imread( path ).astype( float )\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    if img is None: return None\n",
    "    if len(img.shape) < 2: return None\n",
    "    if len(img.shape) == 4: return None\n",
    "    if len(img.shape) == 2: img=np.tile(img[:,:,None], 3)\n",
    "    if img.shape[2] == 4: img=img[:,:,:3]\n",
    "    if img.shape[2] > 4: return None\n",
    "\n",
    "    img /= 255.\n",
    "\n",
    "    short_edge = min( img.shape[:2] )\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy:yy+short_edge, xx:xx+short_edge]\n",
    "    resized_img = skimage.transform.resize( crop_img, [224,224] , mode='constant')     #resize the image here\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector():\n",
    "    def __init__(self, weight_file_path, n_labels):\n",
    "        self.image_mean = [103.939, 116.779, 123.68]\n",
    "        self.n_labels = n_labels\n",
    "\n",
    "        with open(weight_file_path,'rb') as f:\n",
    "            self.pretrained_weights = Pickle.load(f,encoding='iso-8859-1')\n",
    "\n",
    "    def get_weight( self, layer_name):\n",
    "        layer = self.pretrained_weights[layer_name]\n",
    "        return layer[0]\n",
    "\n",
    "    def get_bias( self, layer_name ):\n",
    "        layer = self.pretrained_weights[layer_name]\n",
    "        return layer[1]\n",
    "\n",
    "    def get_conv_weight( self, name ):\n",
    "        f = self.get_weight( name )\n",
    "        return f.transpose(( 2,3,1,0 ))\n",
    "\n",
    "    def conv_layer( self, bottom, name ):\n",
    "        with tf.variable_scope(name) as scope:\n",
    "\n",
    "            w = self.get_conv_weight(name)\n",
    "            b = self.get_bias(name)\n",
    "\n",
    "            conv_weights = tf.get_variable(\n",
    "                    \"W\",\n",
    "                    shape=w.shape,\n",
    "                    initializer=tf.constant_initializer(w)\n",
    "                    )\n",
    "            conv_biases = tf.get_variable(\n",
    "                    \"b\",\n",
    "                    shape=b.shape,\n",
    "                    initializer=tf.constant_initializer(b)\n",
    "                    )\n",
    "\n",
    "            conv = tf.nn.conv2d( bottom, conv_weights, [1,1,1,1], padding='SAME')\n",
    "            bias = tf.nn.bias_add( conv, conv_biases )\n",
    "            relu = tf.nn.relu( bias, name=name )\n",
    "\n",
    "        return relu\n",
    "\n",
    "    def new_conv_layer( self, bottom, filter_shape, name ):\n",
    "        with tf.variable_scope( name ) as scope:\n",
    "            w = tf.get_variable(\n",
    "                    \"W\",\n",
    "                    shape=filter_shape,\n",
    "                    initializer=tf.random_normal_initializer(0., 0.01))\n",
    "            b = tf.get_variable(\n",
    "                    \"b\",\n",
    "                    shape=filter_shape[-1],\n",
    "                    initializer=tf.constant_initializer(0.))\n",
    "\n",
    "            conv = tf.nn.conv2d( bottom, w, [1,1,1,1], padding='SAME')\n",
    "            bias = tf.nn.bias_add(conv, b)\n",
    "\n",
    "        return bias #relu\n",
    "\n",
    "    def fc_layer(self, bottom, name, create=False):\n",
    "        shape = bottom.get_shape().as_list()\n",
    "        dim = np.prod( shape[1:] )\n",
    "        x = tf.reshape(bottom, [-1, dim])\n",
    "\n",
    "        cw = self.get_weight(name)\n",
    "        b = self.get_bias(name)\n",
    "\n",
    "        if name == \"fc6\":\n",
    "            cw = cw.reshape((4096, 512, 7,7))\n",
    "            cw = cw.transpose((2,3,1,0))\n",
    "            cw = cw.reshape((25088,4096))\n",
    "        else:\n",
    "            cw = cw.transpose((1,0))\n",
    "\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            cw = tf.get_variable(\n",
    "                    \"W\",\n",
    "                    shape=cw.shape,\n",
    "                    initializer=tf.constant_initializer(cw))\n",
    "            b = tf.get_variable(\n",
    "                    \"b\",\n",
    "                    shape=b.shape,\n",
    "                    initializer=tf.constant_initializer(b))\n",
    "\n",
    "            fc = tf.nn.bias_add( tf.matmul( x, cw ), b, name=scope)\n",
    "\n",
    "        return fc\n",
    "\n",
    "    def new_fc_layer( self, bottom, input_size, output_size, name ):\n",
    "        shape = bottom.get_shape().to_list()\n",
    "        dim = np.prod( shape[1:] )\n",
    "        x = tf.reshape( bottom, [-1, dim])\n",
    "\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            w = tf.get_variable(\n",
    "                    \"W\",\n",
    "                    shape=[input_size, output_size],\n",
    "                    initializer=tf.random_normal_initializer(0., 0.01))\n",
    "            b = tf.get_variable(\n",
    "                    \"b\",\n",
    "                    shape=[output_size],\n",
    "                    initializer=tf.constant_initializer(0.))\n",
    "            fc = tf.nn.bias_add( tf.matmul(x, w), b, name=scope)\n",
    "\n",
    "        return fc\n",
    "\n",
    "    def inference( self, rgb, train=False ):\n",
    "        rgb *= 255.\n",
    "        \n",
    "        r, g, b = tf.split(rgb, num_or_size_splits=3, axis=3)\n",
    "        bgr = tf.concat(\n",
    "            [\n",
    "                b-self.image_mean[0],\n",
    "                g-self.image_mean[1],\n",
    "                r-self.image_mean[2]\n",
    "            ], axis=3)\n",
    "        '''\n",
    "        #OldTF\n",
    "        r, g, b = tf.split(3, 3, rgb)\n",
    "        bgr = tf.concat(3,\n",
    "            [\n",
    "                b-self.image_mean[0],\n",
    "                g-self.image_mean[1],\n",
    "                r-self.image_mean[2]\n",
    "            ])\n",
    "        '''\n",
    "\n",
    "        relu1_1 = self.conv_layer( bgr, \"conv1_1\" )\n",
    "        relu1_2 = self.conv_layer( relu1_1, \"conv1_2\" )\n",
    "\n",
    "        pool1 = tf.nn.max_pool(relu1_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                                         padding='SAME', name='pool1')\n",
    "\n",
    "        relu2_1 = self.conv_layer(pool1, \"conv2_1\")\n",
    "        relu2_2 = self.conv_layer(relu2_1, \"conv2_2\")\n",
    "        pool2 = tf.nn.max_pool(relu2_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                               padding='SAME', name='pool2')\n",
    "\n",
    "        relu3_1 = self.conv_layer( pool2, \"conv3_1\")\n",
    "        relu3_2 = self.conv_layer( relu3_1, \"conv3_2\")\n",
    "        relu3_3 = self.conv_layer( relu3_2, \"conv3_3\")\n",
    "        pool3 = tf.nn.max_pool(relu3_3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                               padding='SAME', name='pool3')\n",
    "\n",
    "        relu4_1 = self.conv_layer( pool3, \"conv4_1\")\n",
    "        relu4_2 = self.conv_layer( relu4_1, \"conv4_2\")\n",
    "        relu4_3 = self.conv_layer( relu4_2, \"conv4_3\")\n",
    "        pool4 = tf.nn.max_pool(relu4_3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                               padding='SAME', name='pool4')\n",
    "\n",
    "        relu5_1 = self.conv_layer( pool4, \"conv5_1\")\n",
    "        relu5_2 = self.conv_layer( relu5_1, \"conv5_2\")\n",
    "        relu5_3 = self.conv_layer( relu5_2, \"conv5_3\")\n",
    "\n",
    "        conv6 = self.new_conv_layer( relu5_3, [3,3,512,1024], \"conv6\")\n",
    "        gap = tf.reduce_mean( conv6, [1,2] )\n",
    "\n",
    "        with tf.variable_scope(\"GAP\"):\n",
    "            gap_w = tf.get_variable(\n",
    "                    \"W\",\n",
    "                    shape=[1024, self.n_labels],\n",
    "                    initializer=tf.random_normal_initializer(0., 0.01))\n",
    "\n",
    "        output = tf.matmul( gap, gap_w)\n",
    "\n",
    "        return pool1, pool2, pool3, pool4, relu5_3, conv6, gap, output\n",
    "\n",
    "    def get_classmap(self, label, conv6):\n",
    "        conv6_resized = tf.image.resize_bilinear( conv6, [224, 224] )\n",
    "        with tf.variable_scope(\"GAP\", reuse=True):\n",
    "            label_w = tf.gather(tf.transpose(tf.get_variable(\"W\")), label)\n",
    "            label_w = tf.reshape( label_w, [-1, 1024, 1] ) # [batch_size, 1024, 1]\n",
    "\n",
    "        conv6_resized = tf.reshape(conv6_resized, [-1, 224*224, 1024]) # [batch_size, 224*224, 1024]\n",
    "\n",
    "        classmap = tf.matmul( conv6_resized, label_w )\n",
    "        '''\n",
    "        #OldTF\n",
    "        classmap = tf.batch_matmul( conv6_resized, label_w )\n",
    "        '''\n",
    "        \n",
    "        classmap = tf.reshape( classmap, [-1, 224,224] )\n",
    "        return classmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training ...\n",
      "loss 23.968582\n",
      "loss 23.677494\n",
      "loss 23.305138\n",
      "loss 22.297052\n",
      "loss 20.95269\n",
      "loss 19.854774\n",
      "loss 18.243721\n",
      "loss 15.889815\n",
      "loss 12.164985\n",
      "loss 7.6382785\n",
      "======================================\n",
      "Epoch 1 Iteration 10\n",
      "Processed 180 / 4442\n",
      "Training Loss: 18.799252\n",
      "======================================\n",
      "loss 3.5263362\n",
      "loss 1.4366508\n",
      "loss 6.149808\n",
      "loss 10.015748\n",
      "loss 4.8196235\n",
      "loss 1.173717\n",
      "loss 1.4628166\n",
      "loss 3.0647736\n",
      "loss 5.003822\n",
      "loss 5.2884803\n",
      "======================================\n",
      "Epoch 1 Iteration 20\n",
      "Processed 380 / 4442\n",
      "Training Loss: 4.1941776\n",
      "======================================\n",
      "loss 3.4847507\n",
      "loss 3.8622758\n",
      "loss 3.3299222\n",
      "loss 1.8582644\n",
      "loss 1.7809445\n",
      "loss 1.6281078\n",
      "loss 2.9613032\n",
      "loss 2.6239648\n",
      "loss 1.8702688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f3c2aa5baef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m                         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minit_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                         \u001b[0mimages_tf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                         \u001b[0mlabels_tf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_labels_deal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                         })\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 1 # 10000    #times using all the training data traverse \n",
    "init_learning_rate = 0.0001\n",
    "weight_decay_rate = 0.0005\n",
    "momentum = 0.9\n",
    "batch_size = 20\n",
    "\n",
    "now = datetime.now(pytz.timezone('US/Eastern'))\n",
    "seconds_since_epoch_start = time.mktime(now.timetuple())\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    learning_rate = tf.placeholder( tf.float32, [])   #learning rate\n",
    "    images_tf = tf.placeholder( tf.float32, [None, 224, 224, 3], name=\"images\")       #image placeholder\n",
    "\n",
    "    #Modify: placeholder's size\n",
    "    labels_tf = tf.placeholder( tf.float32, [None,44], name='labels')                   #label placeholder\n",
    "\n",
    "    detector = Detector(weight_path,44)\n",
    "\n",
    "    p1,p2,p3,p4,conv5, conv6, gap, output = detector.inference(images_tf)          #return each conv\n",
    "    \n",
    "    #Modify: MSE loss function\n",
    "    loss_tf = tf.losses.mean_squared_error(labels = labels_tf,predictions=output) \n",
    "\n",
    "    weights_only = filter(lambda x: x.name.endswith('W:0'), tf.trainable_variables())\n",
    "    weight_decay = tf.reduce_sum(tf.stack([tf.nn.l2_loss(x) for x in weights_only])) * weight_decay_rate\n",
    "    \n",
    "    #loss_tf += weight_decay                                                        #update\n",
    "    saver = tf.train.Saver( max_to_keep=50 )\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer( learning_rate, momentum )\n",
    "    grads_and_vars = optimizer.compute_gradients( loss_tf )\n",
    "    grads_and_vars = map(lambda gv: (gv[0], gv[1]) if ('conv6' in gv[1].name or 'GAP' in gv[1].name) else (gv[0]*0.1, gv[1]), grads_and_vars)\n",
    "    train_op = optimizer.apply_gradients( grads_and_vars )\n",
    "    \n",
    "with tf.Session(graph=graph) as sess:    \n",
    "    tf.global_variables_initializer().run()\n",
    "    '''\n",
    "    #OldTF\n",
    "    tf.initialize_all_variables().run()\n",
    "    '''\n",
    "\n",
    "    if pretrained_model:\n",
    "        print ('Pretrained model loaded from ' + pretrained_model + ' (this overwrites the initial weights loaded to the model)')\n",
    "        saver.restore(sess, pretrained_model)\n",
    "\n",
    "\n",
    "    iterations = 0\n",
    "    loss_list = []\n",
    "    print ('Starting the training ...')\n",
    "    for epoch in range(n_epochs):\n",
    "        trainset.index = range(len(trainset))\n",
    "        #Shuffle the index of all the trainset\n",
    "        trainset = trainset.loc[np.random.permutation(len(trainset) )]\n",
    "        \n",
    "        for start, end in zip(\n",
    "            range( 0, len(trainset)+batch_size, batch_size),\n",
    "            range(batch_size, len(trainset)+batch_size, batch_size)):\n",
    "\n",
    "            current_data = trainset[start:end]\n",
    "            current_image_paths = current_data['image_path'].values    #return batch imagePaths with type of np array\n",
    "            \n",
    "            #Modify: image path\n",
    "            current_images = np.array(list(map(lambda x: load_image(os.path.join(image_path,x)), current_image_paths)))\n",
    "\n",
    "            good_index = np.array(list(map(lambda x: x is not None, current_images)))\n",
    "\n",
    "            current_data = current_data[good_index]\n",
    "            current_images = np.stack(current_images[good_index])\n",
    "\n",
    "            \n",
    "            # Obtaining the label of each image\n",
    "            # transform it into a None*44 2d matrix\n",
    "            current_labels = np.array(current_data['label'].values)            \n",
    "            current_labels_deal = np.zeros((current_labels.shape[0],44))\n",
    "            for index,row in enumerate(current_labels):\n",
    "                current_labels_deal[index,:] = row\n",
    "            #print(current_labels_deal.shape)\n",
    "            #print(current_labels_deal)\n",
    "            # Run tensorflow session to start train\n",
    "            _, loss_val, output_val = sess.run(\n",
    "                    [train_op, loss_tf, output],\n",
    "                    feed_dict={\n",
    "                        learning_rate: init_learning_rate,\n",
    "                        images_tf: current_images,\n",
    "                        labels_tf: current_labels_deal\n",
    "                        })\n",
    "            \n",
    "            print(\"loss\",loss_val)\n",
    "            loss_list.append(loss_val)   #store the loss value\n",
    "\n",
    "            iterations += 1            \n",
    "            #Print out every 10 iterations\n",
    "            if iterations % 10 == 0:\n",
    "                print (\"======================================\")\n",
    "                print (\"Epoch\", epoch + 1, \"Iteration\", iterations)\n",
    "                print (\"Processed\", start, '/', len(trainset))\n",
    "                print (\"Training Loss:\", np.mean(loss_list))\n",
    "                print (\"======================================\")\n",
    "                loss_list = []\n",
    "        print (\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "        print (\"producing model after epoch:{}\".format(epoch+1))\n",
    "        print (\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "        saver.save( sess, os.path.join(model_path,saved_model_name), global_step=epoch)\n",
    "        init_learning_rate *= 0.99\n",
    "    \n",
    "now = datetime.now(pytz.timezone('US/Eastern'))\n",
    "seconds_since_epoch_end = time.mktime(now.timetuple())\n",
    "print ('Processing took ' + str( np.around( (seconds_since_epoch_end - seconds_since_epoch_start)/60.0 , decimals=1) ) + ' minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
